---
title: 'EdX Data Science/HarvardX PH125.9x: IDV Capstone'
author: "William Mee"
date: "2022-10-02"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This is the final capstone of the *EdX Data Science/HarvardX PH125.9x* course. The
aim of the capstone is to apply machine learning techniques from the course to a novel
dataset.

### Dataset

For my capstone I chose to use the [abalone age](https://archive.ics.uci.edu/ml/datasets/abalone) dataset. This is an older, established dataset but was new to me and not used in
course material. I chose this dataset because it promised to be a good one to better
understand the challenges of machine learning, even if the subject was itself not 
particularly interesting.

The dataset has 4176 observations on abalone (large marine snails)
which was gathered in the 1990's. It has 7 continuous features (weights, diameter etc.),
the abalone sex (male, female or immature/infant) and abalone ring counts, which 
correspond to the age in years. 

| Feature       | Description                               | Type       | Metric 
| :------------ | :---------------------------------------- | :--------- | :-----
| Rings         | Growth rings, indicating the age in years | Integer    | Years
| Sex           | Male, Female or Infant                    | Factor     | M/F/I
| Length        | Longest shell measurement                 | Continuous | Meters
| Diameter      | Dimension perpendicular to length         | Continuous | Meters
| Height        | Total height, including meat              | Continuous | Meters
| WholeWeight   | Whole abalone weight, including meat      | Continuous | Kilograms  
| ShuckedWeight | Weight of meat only                       | Continuous | Kilograms  
| VisceraWeight | Gut weight (after bleeding)               | Continuous | Kilograms 
| ShellWeight   | Shell weight after being dried            | Continuous | Kilograms 


Although this dataset is well-known, I did not look at other work in doing this
capstone, either scientific papers which quote it or online analysis (Medium, Kaggle etc.)

Note: I spent some time looking at an alternative, the [Kepler Exoplanets dataset](https://www.kaggle.com/datasets/keplersmachines/kepler-labelled-time-series-data). While
a more interesting subject, this rapidly lead to analysis which wasn't covered in the
course (time series, fourier transforms etc.) so I decided to not pursue this. Some
other datasets I evaluated are in the references below. 

### Goal and Approach
The challenge is to predict the ring count (age) of the abalone using machine learning
approaches: i.e. to determine if abalone age can be predicted using the other features.

Because the prediction target is integer/numeric, this is a regression (vs classification)
task. I began by transforming the data into an R dataset,
then analyzed and visualized the data, including looking at feature correlation. The dataset required little
cleaning or pre-processing, but I did remove a couple of outliers. I used a standard 
root mean square error (RMSE) function to evaluate the success of predictions, although also
include accuracy and other 'confusion metrics' data occasionally for comparison, treating
the ring count as categories. 

The [caret R framework](https://topepo.github.io/caret/)
provided a convenient approach to explore a variety of different machine learning 
algorithms for the problem: I investigated GLM, KNN and random forest for this work. Further details
and results are given below. 

Beyond comparing different algorithms, I explored feature selection (whether using fewer features 
improved the predictions) as well as whether the combination of sub-models
would improve overall results. 

# Analysis

```{r initialization, echo=FALSE, warning=FALSE, message=FALSE}
library(caret)
library(ggplot2)
library(tidyverse)
library(RColorBrewer)
```

### Data preparation

I downloaded, lightly transformed and saved a local copy of the abalone data with
the following

```{r download-dataset, eval=FALSE, comment=NA, warning=FALSE, message=FALSE}
# Download the Abalone dataset
abalone_tmp <- tempfile()
download.file('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data', abalone_tmp)
# Convert to a dataframe and rename columns
abalone_df <- read.csv(file = abalone_tmp)
colnames(abalone_df) <- c(
  'Sex', 'Length', 'Diameter', 'Height', 'WholeWeight', 
  'ShuckedWeight', 'VisceraWeight', 'ShellWeight', 'Rings'
  )
# Convert the Sex column to a factor
abalone_df$Sex <- as.factor(abalone_df$Sex)
# Save a local copy 
save(abalone_df, file='./edx-datasci/capstone-idv/data/abalone.Rda')
```

```{r load-dataset, echo=FALSE, warning=FALSE, message=FALSE}
load('./data/abalone.Rda')
```

### Data cleaning

The dataset contains no missing features. During visualization and exploration, I caught
only a couple of samples which seemed to be erroneous (height > 50 cm)

```{r clean-dataset, warning=FALSE, message=FALSE}
abalone_df <- abalone_df %>% filter(Height <= 0.5)
```

### Data exploration and visualization

I used *summarize* to obtain the following overviews by sex 

| Sex    | Count | Mean Rings | SD Rings | Min Rings | Max Rings | 
| :----- | :---- | :-------- | :-------- | :--------- | :-------
| Infant |  1342 |  7.89      | 2.51     | 1          | 21
| Female |  1306 | 11.1       | 3.10     | 5          | 29
| Male   |  1526 | 10.7       | 3.03     | 3          | 27

The ring count histograms are as follows:

```{r ring-histograms-by-sex, echo=FALSE, warning=FALSE, message=FALSE}
by_sex_summary <- abalone_df %>%
  group_by(Sex) %>%
  summarize(
    Count=n(), 
    RingsMean=mean(Rings), 
    RingsSd=sd(Rings),
    ShellWeightMean=mean(ShellWeight), 
  )

color_palette <- 'Set2'

abalone_df %>%
  ggplot(aes(x=Rings, color=Sex)) +
  geom_histogram(binwidth=1, aes(fill=Sex), alpha=0.5) +
  geom_vline(data=by_sex_summary, aes(xintercept=RingsMean),
             linetype='dashed',  color='Red') +
  labs(title='Abalone Ring Histograms by Sex with Means', x='Rings', y = 'Count') +
  scale_colour_brewer(palette = color_palette) +
  scale_fill_brewer(palette = color_palette) +
  facet_grid(Sex ~ .)
```

I extracted summary data including correlations of the numeric features with the ring count, which are summarized below.

| Feature       | Min | Max | Rings Correlation 
| :------------ | :-- | :-- | :----------------
| Rings         | 1   | 29  | 1
| Length        |0.075  |  0.815 | 0.557
| Diameter      |0.055  | 0.65 | 0.575
| Height        | 0 | 0.25 | 0.61 
| WholeWeight   | 0.002 | 2.8255 | 0.541
| ShuckedWeight | | | 0.422
| VisceraWeight | | | 0.505 
| ShellWeight   | | | 0.628 

Histograms of the features broken down by sex are also intersting: below is
that of *ShellWeight*

```{r shell-weight-histograms-by-sex, echo=FALSE, warning=FALSE, message=FALSE}
abalone_df %>%
  ggplot(aes(x=ShellWeight, color=Sex)) +
  geom_histogram(aes(fill=Sex), alpha=0.5) +
  geom_vline(data=by_sex_summary, aes(xintercept=ShellWeightMean),
             linetype='dashed',  color='Red') +
  labs(title='Abalone ShellWeight Histograms by Sex with Means', x='ShellWeight', y = 'Count') +
  scale_colour_brewer(palette = color_palette) +
  scale_fill_brewer(palette = color_palette) +
  facet_grid(Sex ~ .)
```

I then looked at scatter plots of some of the features against the ring count; 
for example here is *Height* vs *Rings*.

```{r ring-vs-height-scatterplot, echo=FALSE, warning=FALSE, message=FALSE}
abalone_df %>%
  ggplot(aes(x=Rings, y=Height, color=Sex)) +
  geom_point(aes(fill=Sex), alpha=0.8) +
  scale_colour_brewer(palette = color_palette) +
  labs(title='Abalone Ring Count vs Height', x='Rings', y = 'Height (m)') 

```

### Insights

There are several relevant insights based on the above analysis and visualizations:

* the majority of observations have rings in the middle range
independent of Sex (i.e. even for infant abalone): the prevalence of very young or very old abalone is small. 
* the classification of *Infant* is unclear from the data: there are older abalone
which are classified as infant and very young ones which are not.
* features such as *ShellWeight* have a normal distribution for the adult 
populations, but not for the infant one:
* All the numeric features are positively correlated to Rings, with *Height* and *ShellWeight*
having the greatest correlation. 
* From the scatter plot of *Rings* vs *Height* it seems there is strong correlation
for the infant population. This is confirmed by breaking down the correlation 
by *Sex* which gives a correlation of **0.720** for infant abalone vs **0.450** for
male and **0.342** for female. An intuition here is that the infant
abalone are in a stronger growth phase.

Several of the above insights indicated that using sub-models based on the *Sex*
feature might improve predictions.

### Modeling and Loss Function

I split the dataset into 90% train and 10% test partitions:

```{r split-train-test, warning=FALSE, message=FALSE}
set.seed(51, sample.kind = 'Rounding')
test_index <- createDataPartition(abalone_df$Rings, times = 1, p = 0.1, list = FALSE)
abalone_test <- abalone_df[test_index, ]
abalone_train <- abalone_df[-test_index, ]  
```

I then looked at the results of 3 regression models: *GLM*, *kNearestNeighbors* and *Random Forest*,
including parameter selection.

I used the standard RMSE (root mean square error) as a loss function. The regression
models all produced fractional ring predictions, so strictly the results should be
rounded, but I explored both and the difference was small. I decided to use the
non-rounded RMSE function because the age represented by the rings is continuous.

```{r rmse}
rmse <- function(y_hat, y) {
  sqrt(sum((y_hat - y)^2)/length(y_hat))
}

```

Converting the rings to categories and then looking at the confusion matrix was also
informative.

# Results

### General Linear Model (GLM)

I used GLM to achieve an initial baseline

```{r glm}
train_glm <- train(Rings ~ ., method = 'glm', data = abalone_train)
rings_pred_glm <- predict(train_glm, abalone_test, type = 'raw')
```

This GLM RMSE was 2.160 with an accuracy of 0.237

I explored turning the ring counts into factors and looking at the classification
metrics 

```{r glm-confusion-matrix}
all_rings <- seq(1, 29)
cm_glm <- confusionMatrix(
  data = factor(round(rings_pred_glm), all_rings), 
  reference = factor(abalone_test$Rings, all_rings)
)

cm_glm$overall
cm_glm$byClass[,c("Prevalence", "F1", "Sensitivity", "Precision", "Recall")]
```

This data showed the variance in prevalence, and how the F1 score varied with rings.
A simple visualization of the prediction errors by ring showed how many of the higher
rings (above 13) had only errors.

```{r glm-error-histogram, echo=FALSE}
glm_errors = data.frame(
  Sex = abalone_test$Sex,
  Rings = abalone_test$Rings,
  RingsPredicted = rings_pred_glm,
  Accurate = round(rings_pred_glm) == abalone_test$Rings,
  Error = abalone_test$Rings - rings_pred_glm
)

# look at the error distribution
glm_errors %>%  
ggplot(aes(x=Rings, color=Accurate)) +
  geom_histogram(binwidth=1, aes(fill=Accurate), alpha=0.5) +
  labs(title='GLM Errors', x='Rings', y = 'Error Count')
```

Plotting the mean error (difference between predicted and actual ring count)
shows an interesting trend: the model predicts increasingly lower counts for high ring count abalone i.e. it is not successful for these older observations, probably due to prevalence.

```{r glm-error-line, echo=FALSE}
glm_errors %>%
  group_by(Rings) %>%
  summarize(meanError = mean(Error)) %>%
  ggplot(aes(x=Rings, y=meanError)) + 
  geom_line(color='orange') +
  geom_hline(yintercept=0, linetype='dashed', color = 'blue') +
  labs(title='Mean prediction error by Ring', x='Rings', y = 'Mean ring error')
```

### K-Nearest Neighbors

Switching to the KNN algorithm, the optimal k parameter for the entire dataset was **23**

```{r knn}
train_knn <- train(Rings ~ ., method = 'knn', 
                   data = abalone_train,
                   tuneGrid = data.frame(k = seq(3, 71, 2)))
rings_pred_knn <- predict(train_knn, abalone_test, type = 'raw')
```

This gave an RMSE of 2.185 and an accuracy of 0.239, i.e. little difference
to the GLM model. Using KNN, I explored using less features, selecting
the three most correlated features *ShellWeight*, *Diameter* and *Height* but the
RMSE degraded to 2.250.

I then used KNN to explore the idea of Sex-specific models. Training a new model
on just the infant abalone gave a significantly lower RMSE of 1.651803
```{r knn-infant-only}
abalone_train_i <- abalone_train %>% filter(Sex == 'I') %>% select(!Sex)
abalone_test_i <- abalone_test %>% filter(Sex == 'I') %>% select(!Sex)
train_knn_i <- train(Rings ~ ., method = 'knn', data = abalone_train_i, tuneGrid = data.frame(k = seq(15, 30, 2)))
rings_pred_knn_i <- predict(train_knn_i, abalone_test_i, type = 'raw')
```
The equivalent male and female RMSEs were 2.071 and 2.820 respectively, i.e. the
female RMSE increased significantly. The overall RMSE on the simple combination of these three models
was however 2.191, worse than the orginal. 

### Random Forest

As a final algorithm, I trained a random forest algorithm

```{r random-forest, warning=FALSE, message=FALSE}
library(randomForest)
train_rf <- randomForest(Rings ~ ., data = abalone_train) 
rings_pred_rf <- predict(train_rf, abalone_test)
```

The achieved RMSE here - 2.112 - was slightly better than the GLM one. The 
mean prediction errors by ring count showed a similar pattern to GLM. The model
had low errors for rings up to about 13, but for higher ring counts became 
increasingly inaccurate, again predicting fewer rings.

```{r random-forest-errors-plot, echo=FALSE}
data.frame(Rings=abalone_test$Rings, Error=abalone_test$Rings - rings_pred_rf) %>%
  group_by(Rings) %>%
  summarize(meanError = mean(Error)) %>%
  ggplot(aes(x=Rings, y=meanError)) + 
  geom_line(color='orange') +
  geom_hline(yintercept=0, linetype='dashed', color = 'blue') +
  labs(title='Mean prediction error by Ring: Random Forest', x='Rings', y = 'Mean ring error')
```

# Conclusion
A summary of the measured RMSE errors for different approaches that I obtained
are in the table below.

| Algorithm            | RMSE
| :------------------- | :----
| GLM                  | 2.160
| KNN                  | 2.185
| KNN with 3 features  | 2.230
| KNN composite        | 2.191
| Random Forest        | 2.112 

I was unable to substantially lower the RMSE using different algorithms or 
approaches. The ring prediction was only accurate in 23% of the test observations
in the best case. This was however interesting work: it demonstrated how
sub-populations can be significantly easier to predict than a general population,
and also showed the issue of prevalence very clearly. It was also interesting to
observe that an algorithm like KNN can handle sub-populations better than I 
was expecting. 

I think in future work
I'd like to explore the prevalence issue more: looking at techniques which can handle
a very skewed distribution of observations. I'd also like to look at the work
of others with this dataset: since it's relatively old it has been used many 
times in research and learning.

# References

### Dataset repositories

- [UCI Machine Learning Repository](https://archive-beta.ics.uci.edu/)
- [Datasets/Kaggle](https://www.kaggle.com/datasets)
- [ML-Friendly Public Datasets/Kaggle](https://www.kaggle.com/code/annavictoria/ml-friendly-public-datasets/notebook)

### Datasets

- [Abalone Age](https://archive.ics.uci.edu/ml/datasets/abalone) and at [Kaggle](https://www.kaggle.com/datasets/rodolfomendes/abalone-dataset)
- [Kepler Exoplanets](https://www.kaggle.com/datasets/keplersmachines/kepler-labelled-time-series-data)
- [Star types](https://www.kaggle.com/datasets/deepu1109/star-dataset)
- [Pancreatic Cancer](https://www.kaggle.com/datasets/johnjdavisiv/urinary-biomarkers-for-pancreatic-cancer) See also [Visualization talk](https://www.kaggle.com/code/johnjdavisiv/indiana-mlrc-data-visualization-in-r)
